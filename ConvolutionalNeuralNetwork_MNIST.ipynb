{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "Size of:\n",
      "- Training-set:\t\t55000\n",
      "- Test-set:\t\t10000\n",
      "- Validation-set:\t5000\n"
     ]
    }
   ],
   "source": [
    "data = input_data.read_data_sets('data/MNIST/', one_hot=True)\n",
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(len(data.train.labels)))\n",
    "print(\"- Test-set:\\t\\t{}\".format(len(data.test.labels)))\n",
    "print(\"- Validation-set:\\t{}\".format(len(data.validation.labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer1_filter_size = 5\n",
    "conv_layer2_filter_size = 5\n",
    "conv1_num_filters = 16\n",
    "conv2_num_filters = 64\n",
    "hidden_layer1_input_size = 7*7*64\n",
    "hidden_layer1_size = 128\n",
    "hidden_layer2_size = 64\n",
    "image_size = 28\n",
    "imageflat_size = image_size*image_size\n",
    "num_channel = 1\n",
    "num_classes = 10\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_convolution_layer(input, filter_size, num_filters, num_channel, polling=True):\n",
    "    shape = [filter_size, filter_size, num_channel, num_filters]\n",
    "    weights = tf.Variable(tf.truncated_normal(shape=shape,stddev=0.05))\n",
    "    #biases = tf.Variable(tf.truncated_normal(shape=[num_filters],stddev=0.05))\n",
    "    layer = tf.nn.conv2d(input, filter = weights,strides=[1,1,1,1], padding = \"SAME\")\n",
    "    #layer+= biases\n",
    "    layer = tf.nn.max_pool(layer,[1,2,2,1],strides = [1,2,2,1], padding= \"SAME\")\n",
    "    layer = tf.nn.relu(layer)\n",
    "    return layer\n",
    "\n",
    "def new_full_connected_layer(input, input_size, layer_size,bias =True):\n",
    "    weights = tf.Variable(tf.truncated_normal(shape=(input_size, layer_size)))\n",
    "    logit = tf.matmul(input,weights)\n",
    "    if bias:\n",
    "        biases = tf.Variable(tf.truncated_normal(shape=(1, layer_size)))\n",
    "        logit += biases\n",
    "    \n",
    "    return logit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tf.placeholder(tf.float32, (None,imageflat_size))\n",
    "labels = tf.placeholder(tf.float32, (None, num_classes))\n",
    "is_training = tf.placeholder(tf.bool, (None))\n",
    "input_image = tf.reshape(input,shape=(-1,image_size,image_size,num_channel))\n",
    "\n",
    "conv_layer1 = new_convolution_layer(input_image, conv_layer1_filter_size, conv1_num_filters, num_channel)\n",
    "conv_layer2 = new_convolution_layer(conv_layer1, conv_layer2_filter_size, conv2_num_filters, conv1_num_filters)\n",
    "fc_input_shape = conv_layer2.shape[1]*conv_layer2.shape[2]*conv_layer2.shape[3]\n",
    "flat_conv2_output = tf.reshape(conv_layer2,shape=[-1,fc_input_shape])\n",
    "\n",
    "fc_hidden_layer1 = new_full_connected_layer(flat_conv2_output, hidden_layer1_input_size, hidden_layer1_size,bias = False)\n",
    "fc_hidden_layer1 = tf.layers.dropout(fc_hidden_layer1, rate=0.5, training=is_training)\n",
    "#fc_hidden_layer2 = new_full_connected_layer(tf.sigmoid(fc_hidden_layer1), hidden_layer1_size, hidden_layer2_size)\n",
    "logits = new_full_connected_layer(tf.sigmoid(fc_hidden_layer1), hidden_layer1_size, num_classes)\n",
    "\n",
    "nn_output = tf.nn.softmax(logits)\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels)\n",
    "cost=tf.reduce_sum(cross_entropy)\n",
    "\n",
    "learning_rate = tf.placeholder(tf.float32,shape = [])\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "true_output = tf.argmax(labels,axis = 1)\n",
    "output_nn = tf.argmax(nn_output, axis = 1)\n",
    "\n",
    "correct_prediction = tf.equal(output_nn, true_output)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "#sess.run(conv_layer1, feed_dict={input:[data.train.images[0]]}).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_count = 0\n",
    "def fit(num_iterations,learningrate):\n",
    "    global iter_count\n",
    "    \n",
    "    for i in range(iter_count,iter_count+num_iterations):\n",
    "        input_next_batch, label_next_batch = data.train.next_batch(batch_size)\n",
    "        feed_dict_train = {input:input_next_batch, labels:label_next_batch, learning_rate: learningrate,is_training : True}\n",
    "        sess.run(optimizer,feed_dict=feed_dict_train)\n",
    "        if i%100 == 0:\n",
    "            feed_dict_train = {input:input_next_batch, labels:label_next_batch, learning_rate: learningrate,is_training: False}\n",
    "            acc, loss= sess.run([accuracy, cost], feed_dict=feed_dict_train)\n",
    "            print(\"Iteration {0}, Accuracy {1:.4f}%\".format(i+1,acc*100))\n",
    "    iter_count += num_iterations\n",
    "feed_dict_test = {input:data.test.images[0:500], labels:data.test.labels[0:500],is_training: False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 15.600000321865082%\n",
      "Iteration 1, Accuracy 17.0000%\n",
      "Iteration 101, Accuracy 89.0000%\n",
      "Iteration 201, Accuracy 98.0000%\n",
      "Iteration 301, Accuracy 95.0000%\n",
      "Iteration 401, Accuracy 98.0000%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy {}%\".format(sess.run(accuracy, feed_dict= feed_dict_test)*100))\n",
    "fit(500,0.001)\n",
    "#print(\"Accuracy {}%\".format(sess.run(accuracy, feed_dict= feed_dict_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 97.39999771118164%\n",
      "Iteration 501, Accuracy 97.0000%\n",
      "Iteration 601, Accuracy 100.0000%\n",
      "Iteration 701, Accuracy 96.0000%\n",
      "Iteration 801, Accuracy 98.0000%\n",
      "Iteration 901, Accuracy 96.0000%\n",
      "Iteration 1001, Accuracy 97.0000%\n",
      "Iteration 1101, Accuracy 99.0000%\n",
      "Iteration 1201, Accuracy 98.0000%\n",
      "Iteration 1301, Accuracy 97.0000%\n",
      "Iteration 1401, Accuracy 100.0000%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy {}%\".format(sess.run(accuracy, feed_dict= feed_dict_test)*100))\n",
    "fit(1000,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 98.60000014305115%\n",
      "Iteration 1501, Accuracy 100.0000%\n",
      "Iteration 1601, Accuracy 100.0000%\n",
      "Iteration 1701, Accuracy 100.0000%\n",
      "Iteration 1801, Accuracy 99.0000%\n",
      "Iteration 1901, Accuracy 100.0000%\n",
      "Iteration 2001, Accuracy 99.0000%\n",
      "Iteration 2101, Accuracy 100.0000%\n",
      "Iteration 2201, Accuracy 100.0000%\n",
      "Iteration 2301, Accuracy 99.0000%\n",
      "Iteration 2401, Accuracy 100.0000%\n",
      "Iteration 2501, Accuracy 99.0000%\n",
      "Iteration 2601, Accuracy 98.0000%\n",
      "Iteration 2701, Accuracy 100.0000%\n",
      "Iteration 2801, Accuracy 100.0000%\n",
      "Iteration 2901, Accuracy 98.0000%\n",
      "Iteration 3001, Accuracy 99.0000%\n",
      "Iteration 3101, Accuracy 100.0000%\n",
      "Iteration 3201, Accuracy 99.0000%\n",
      "Iteration 3301, Accuracy 99.0000%\n",
      "Iteration 3401, Accuracy 100.0000%\n",
      "Iteration 3501, Accuracy 98.0000%\n",
      "Iteration 3601, Accuracy 100.0000%\n",
      "Iteration 3701, Accuracy 100.0000%\n",
      "Iteration 3801, Accuracy 98.0000%\n",
      "Iteration 3901, Accuracy 99.0000%\n",
      "Iteration 4001, Accuracy 99.0000%\n",
      "Iteration 4101, Accuracy 100.0000%\n",
      "Iteration 4201, Accuracy 100.0000%\n",
      "Iteration 4301, Accuracy 99.0000%\n",
      "Iteration 4401, Accuracy 100.0000%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy {}%\".format(sess.run(accuracy, feed_dict= feed_dict_test)*100))\n",
    "fit(3000,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 99.59999918937683%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy {}%\".format(sess.run(accuracy, feed_dict= feed_dict_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(3000,0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
